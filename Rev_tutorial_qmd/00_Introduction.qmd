---
title: "00-Introduction"
---

```{r}
#| label: load_packages
#| echo: false

# Load required packages

pacman::p_load(
  ## data manipulation
  dplyr, tibble, tidyverse, broom, broom.mixed,
  
  ## model fitting
  ape, arm, brms, broom.mixed, cmdstanr, emmeans, glmmTMB, MASS, phytools, rstan, TreeTools,
  
  ## model checking and evaluation
  DHARMa, loo, MuMIn, parallel,
  
  ## visualisation
  bayesplot, ggplot2, patchwork, tidybayes,
  
  ## reporting and utilities
  gt, here, kableExtra, knitr
)
```

Some of the models in this tutorial take a long time to run. To make the tutorial faster and easier to follow, we have precomputed selected models and saved them as `.rds` files.

If you would like to re-run the code yourself and reproduce the results shown in the tutorial, please make sure to do the following:

1.  Download the following files:

    -   online_tutorial.qmd (the source file for this website)

    -   All datasets in the data folder

    -   The precomputed `.rds` files from Google Drive Google Drive link: <https://drive.google.com/drive/folders/1CvshmYMowXSB9MdbCprP1LP7llZNxIbe?usp=drive_link>

2.  Create a folder structure like this on your machine:

```{r}
#| eval: false

    your-project-folder/
    ├── online_tutorial.qmd
    ├── data/
    │   └── (CSV files)
    └── Rdata/
        └── (RDS files from Google Drive)
```

3.  Adjust file paths if your folder structure is different. We use `here::here()`to help make paths more portable, but if you move or rename files/folders, make sure to update functions like `readRDS()` or `read.csv()` accordingly:

```{r}
#| eval: false

# this is example

dat <- read.csv(here("data", "XXX.csv"), header = TRUE) 
brms_m1 <- readRDS(here("Rdata", "brms_m1.rds"))
```

You will see similar code snippets throughout the tutorial. Feel free to modify them based on your own setup. If everything is placed correctly, the `.qmd` file should run without any issues.


This tutorial provides a step-by-step guide to applying location-scale models in ecology, evolution, and environmental sciences. We focus on practical applications and demonstrate how to implement these models in `R` using the `glmmTMB` and `brms` packages.

After a brief introduction to both modeling frameworks, we present worked examples using real datasets. In the final section, we also discuss approaches for model comparison and selection.

# Preparation

## Load required packages

Our tutorial uses `R` statistical software and existing `R` packages, which you will first need to download and install.

This tutorial makes use of several `R` packages for data manipulation, model fitting, diagnostics, visualisation, and reporting:

-   `dplyr`, `tibble`, `tidyverse` - for efficient and tidy data manipulation.

-   `brms`, `glmmTMB`, `arm` - for fitting generalised linear mixed models.

-   `cmdstanr` - interfaces with the CmdStan backend to accelerate Bayesian sampling via within-chain parallelisation. is a C++ library for Bayesian inference, in order to enable within-chain parallelisation to speeding up the sampling process.

-   `DHARMa`, `loo`, `MuMIn` - for model diagnostics, cross-validation, and multi-model inference (note that both `loo` and `Mumin` contain functions with the same names, so call them with explicit namespaces, e.g. `loo::loo( )`).

-   `ggplot2`, `patchwork`, `bayesplot`, `tidybayes` - for flexible and publication-ready visualisations.

-   `gt`, `kableExtra`, `knitr` - for creating clean tables.

-   `here` - for consistent file path management across projects.

-   `ape`, `TreeTools` - for phylogenetic analyses and tree manipulation.

```{r}
#| label: load_packages

# Load required packages

pacman::p_load(
  ## data manipulation
  dplyr, tibble, tidyverse, broom, broom.mixed,
  
  ## model fitting
  ape, arm, brms, broom.mixed, cmdstanr, emmeans, glmmTMB, MASS, phytools, rstan, TreeTools,
  
  ## model checking and evaluation
  DHARMa, loo, MuMIn, parallel,
  
  ## visualisation
  bayesplot, ggplot2, patchwork, tidybayes,
  
  ## reporting and utilities
  gt, here, kableExtra, knitr
)
```

## `glmmTMB` vs `brms`

`glmmTMB` is a powerful and flexible `R` package for fitting generalized linear mixed models (GLMMs), including models with random effect structures and scale (dispersion) part. It is built on the Template Model Builder (TMB) framework, which allows fast and efficient maximum likelihood estimation even for large and complex models.

`brms` is an `R` package that allows users to fit Bayesian generalized (non-)linear multilevel models using the probabilistic programming language Stan. It provides a user-friendly formula syntax similar to that of `lme4` or `glmmTMB`, and supports a wide range of distributions, link functions, and advanced model components, including location-scale modeling.

Both packages are suitable for fitting location-scale models and are widely used in ecology and its related fields. Therefore, we selected them to illustrate how location-scale models can be practically applied in real data analysis.

While `brms` is a powerful and flexible package for Bayesian regression modeling, some readers may not be familiar with its usage. Below, we provide a brief introduction to fitting models using `brms`, focusing on the basic location-scale structure and key functions relevant to our analysis. You can also find some examples each section…

If you get stuck or are unsure about something, it might be helpful to check the below:

-   <https://paulbuerkner.com/brms/index.html>

-   <https://discourse.mc-stan.org/>

This example shows how to fit a simple location-scale model, where both the mean ($\mu$) and the variability ($\sigma$) of a continuous outcome variable $y$ are modeled as functions of a predictor $x$. Note that, throughout this tutorial, we explicitly write `y ~ 1 + x` to indicate that the model includes an intercept. However, `y ~ x` also includes an intercept by default, so both formulations are equivalent.

```{r}
#| eval: false

# Example dataset
# y is continuous response, x is a predictor
# specify the model using bf()
formula1 <- bf(
  y ~ 1 + x,  # location part
  sigma = ~ 1 + x # scale part - specified by sigma
)

# generate default priors based on the formula and data
default_priors <- default_prior(
                        formula1,
                        data = dat,                             
                        family = gaussian()                               
                          )

# fit the model - you can change N of iter, warmup (and thin), and also chains.
  m1 <- brm(formula1,
                  data = dat,           
                  family = gaussian(),                   
                  prior = default_priors,                
                  iter = 2000,   # total iterations per Markov-chain (i.e., how many posterior samples are drawn, including warm-up)
                  warmup = 1000, # number of early draws used only for adapting the sampler (step-size, mass matrix). These samples are discarded
                  thin = 1,      # keep every n-th post-warm-up draw. 1 means keep all draws                    
                  chains = 2,    #  number of independent MCMC chains run in parallel. Provides a convergence check (via Rhat)                    
             )
summary(m1)
```

After fitting the model, you can use `summary(m1)` to inspect the estimated coefficients and sigma with 95% Credible Intervals, along with diagnostic statistics such as Rhat and effective sample size. To better understand how to interpret the model output, please refer to the “**Bonus - brms**” part in the next section.

### Parallel Processing

Before fitting our models with `brms`, we configure some global options to optimize sampling speed using parallel processing:

1.  `parallel::detectCores()`: This function automatically detects the number of logical CPU cores available on your machine. This is a convenient way to ensure your code adapts to different computing environments.
2.  `options(mc.cores = parallel::detectCores())`: The mc.cores option is a global setting primarily used by rstan (the engine behind brms). It controls the number of MCMC chains that will be run in parallel. By setting it to `detectCores()`, you are telling brms to run as many chains concurrently as your CPU allows, significantly speeding up the overall sampling process.
3.  `options(brms.threads = 6)`: The brms.threads option specifies the number of CPU threads that Stan's internal operations can utilize within a single MCMC chain. This enables within-chain parallelisation, further accelerating computations, especially for complex or large datasets. The value 6 is an example; you can adjust this based on your specific CPU architecture and memory.

::: {.callout-tip appearance="simple" icon="false"}
Threading is a powerful feature that enables you to split a chain into multiple parallel threads, significantly reducing computation time. However, it requires installing both `cmdstanr` and the underlying `CmdStan` backend.

```{r}
#| code-fold: true
#| eval: false
#| label: Set up CmdStan and confirm proper installation
cmdstanr::install_cmdstan()
cmdstanr::check_cmdstan_toolchain()
cmdstanr::cmdstan_version()

```
:::

These settings are crucial for making Bayesian model fitting with `brms` more efficient, particularly for complex models or large datasets.

```{r}
parallel::detectCores()

options(mc.cores = parallel::detectCores())

options(brms.threads = 6)  # Set global default
```

::: {.callout-tip appearance="simple" icon="false"}
`brms` models can be computationally intensive and take a significant amount of time to run. To streamline your workflow, we provide the pre-fit models in RDS files, allowing you to load them directly without needing to re-run the lengthy estimation process.
:::

## Specifying the Scale Component

Here's how the scale component is handled in `glmmTMB` and `brms`, along with common parameter names for various distributions:

| Distribution | Scale Parameter (Example) | `glmmTMB` Specification | `brms` Specification (Example) |
|:-----------------|:-----------------|:-----------------|:-----------------|
| Gaussian | $\sigma$ | `dispformula = ~ ...` | `bf(..., sigma ~ ...)` |
| Negative Binomial | $\theta$ | `dispformula = ~ ...` | `bf(..., shape ~ ...)` |
| Conway-Maxwell-Poisson | $\nu$ | `dispformula = ~ ...` | `bf(..., nu ~ ...)` |
| Beta-Binomial | $\phi$ | `dispformula = ~ ...` | `bf(..., phi ~ ...)` |

*Note: In `glmmTMB`, `dispformula` is generally used to model the dispersion or scale parameter, regardless of its specific Greek letter notation, which varies by distribution.*

The scale part varies depending on the distribution: for example, $\sigma$ for Gaussian or $\theta$ for negative binomial, $\nu$ for Conway–Maxwell–Poisson, $\phi$ for beta- binomial distribution (see the main text).